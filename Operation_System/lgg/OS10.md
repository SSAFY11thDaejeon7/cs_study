# 10강

# Virtual Memory Management(가상 메모리 관리)

**Virtual Memory(가상 메모리)**

- non-continuous allocation (사용자 프로그램을 block 단위로 분할하여 적재/실행
- paging / segmentation system

**Virtual Memory Management**

목적 : 가상 메모리 시스템 성능 최적화

cost model(성능 지표), 다양한 최적화 기법

**가장 대표적인 cost model**

**page fault frequency, page fault rate**

page fault를 최소화 해야함. (context switch및 kernel 개입을 최소화하여 시스템 성능 향상)

**용어**

- page reference string(page 참조 문자열)
    
    프로세스의 수행 중 참조한 페이지 번호 순서
    
    ![image](https://github.com/SSAFY11thDaejeon7/cs_study/assets/138864974/37897316-edab-45d0-99ca-a9fa467e02a0)
    
    |w| : 프로세스가 수행되면서 참조한 page 총 개수
    

가상 메모리 사용하기 위한 여러 component들이 있다.

**HW component**

- Address translation device(주소 사상 장치)
    
    TLB, Dedicated page-table register, cache memories
    
- Bit Vectors
    
    page 사용 상황에 대한 정보를 기록하는 비트들 (해당 프로세스에게 할당된 page frame이 꽉 찼을 때 어떤 page frame을 비워줘야할지 등 기준을 정하기 위한 정보들)
    
    - reference bits (used bits) : 참조 비트
    - update bits (modified bits, write bits, dirty bits) : 갱신 비트
    
    ![image](https://github.com/SSAFY11thDaejeon7/cs_study/assets/138864974/3f948403-e796-4871-993a-67c57bc75169)
    

**reference bits 참조 비트**

메모리에 적재된 각각의 page frame이 최근에 참조되었는지를 표시

프로세스에 의해 참조되면 해당 page의 reference bit를 1로 표시

주기적으로 0으로 초기화해준다.

reference bit로 최근에 참조된 page를 확인 가능 → locality 특성 사용

**update bits 갱신 비트**

page가 메모리에 적재된 후, 프로세스에 의해서 수정되었는지를 표시

주기적 초기화 없음. 쓰여질때만 update

update bit = 1은 main memory page frame ≠ swap device page 내용 을 뜻함.

swap device로 다시 갈때, 해당 내용을 **write back** 해주는 작업 필요

**HW component**

1. Allocation strategies
    
    각 프로세스에게 메모리를 얼만큼 줄 것인가?
    
    - fixed allocation(고정 할당) : 프로세스의 실행 동안 고정된 크기의 메모리 할당
    - variable allocation(가변 할당) : 프로세스의 실행 동안 가변적 크기로 메모리 할당
    
    고려사항
    
    프로세스 실행에 필요한 메모리 양을 잘 예측해야함.
    
    if 너무 큰 메모리 할당 → 메모리 낭비
    
    if 너무 작은 메모리 할당 → page fault rate 증가, 시스템 성능 저하
    
2. fetch strategies
    
    특정 page를 언제 메모리에 적재할 것인가?
    
    - Demand fetch (demand paging)
        
        필요할 때 가져옴. 프로세스가 참조하는 페이지들만 적재
        
        하지만 page fault overhead. page fault가 일어날 때 가져오는 구조이므로
        
    - Anticipatory fetch (pre-paging)
        
        참조될 가능성이 높은 page 예측해서 fetch.
        
        예측 성공시 page fault overhead가 발생하지 않는다.
        
        하지만 prediction overhead(kernel의 개입 발생)
        
    
    대부분은 demand fetch를 사용한다. 하지만 사용자가 만든 프로그램인 경우, pre-paging을 사용하는 것이 성능 향상될 수도 있다.
    
3. placement strategies
    
    page/ segment를 어디에 적재할 것인가?
    
    page system에서는 불필요. segmentation system만 해당.
    
    앞에서 배웠던 first-fit, best-fit, worst-fit, next-fit
    
4. replacement strategies
    
    새로운 page를 어떤 page와 교체할 것인가?
    
    (빈 page frame이 없는 경우)
    
5. cleaning strategies
    
    변경된 page를 언제 write back 할 것인가?
    
    변경된 내용을 swap device에 반영
    
    - Demand cleaning
        
        해당 page가 memory에서 내려올 때 write back
        
    - Anticipatory cleaning (pre-cleaning)
        
        더 이상 변경될 가능성이 없다고 판단될 때, 미리 cleaning 수행
        
    
    대부분 demand cleaning 사용함.
    
6. Load(부하) Control Strategies
    
    시스템의 multi-programming degree 조절
    
    적정 수준의 multi-programming degree를 유지해야함. Plateau(고원 영역)
    
    if 너무 낮은 multi-programming degree → 저부하 상태(자원 낭비, 성능 저하)
    
    if 너무 높은 multi-programming degree → 고부하 상태(자원에 대한 경쟁 심화, 성능 저하) Thrashing 현상 발생. (과도한 page fault 발생)

   ![image](https://github.com/SSAFY11thDaejeon7/cs_study/assets/138864974/8813729b-332d-4490-8d4f-6e5389597366)



   가상 메모리 관리를 위한

**SW Component**

**Locality** 가 메모리 관리할 때도 중요하다.

Locality 때문에 특정 몇 개의 페이지만을 프로세스가 집중적으로 참조하는 특성이 생김. 그래서 page fault를 최소화 시킬 때 활용할 수 있다.

## Replacement strategies

![image](https://github.com/SSAFY11thDaejeon7/cs_study/assets/138864974/928c1af3-9c14-443d-8506-16f598ac53ea)

**Fixed Allocation**

해당 프로세스에게 정해진 page만큼 page frame을 할당해주는 기법

그 상황에서 page frame이 다 찼을 때,  누굴 교체할 것이냐 → replacement strategies

- Min algorithm
    
    page fault를 minimize한다.
    
    앞으로 가장 오랫동안 참조되지 않을 page를 replace한다. 가장 이상적이지만 비현실적. 미래 예측 불가.
    
- FIFO algorithm
    
    가장 오래된(먼저 들어온) page를 교체한다.
    
    page가 적재된 시점을 기억하고 있어야 함.
    
    Locality 고려가 전혀 없음. (먼저 들어온 page가 최근에 많이 사용되고 있을 수 있으므로)
    
    FIFO analomy : locality 고려가 없으므로, fixed allocation 할당 page frame수를 늘려줘도 오히려 page fault가 더 많이 발생하는 상황이 생김.
    
- LRU(Least Recently Used) algorithm
    
    가장 오랫동안 참조되지 않은 page를 우선적으로 교체(locality 반영)
    
    page 참조시마다 시간을 기록해야함. (overhead)
    
    locality 기반이므로 Min algorithm과 거의 유사한 성능. 실제로도 많이 사용되는 기법.
    
    단점 : loop 실행 시에 loop당 필요한 page보다 할당받은 page frame이 적은 경우, 무한으로 page fault가 발생하는 상황이 생김. → page frame allocation을 늘려주어 해결 가능.
    
- LFU(Least Frequently Used) algorithm
    
    가장 참조 횟수가 적은 page를 교체. 동점 상황이 생길 수 있으므로 그땐 tie-breaking rule 규칙 필요.
    
    참조 ‘횟수’이므로 LRU보단 low overhead
    
    참조 횟수도 locality를 반영한 것이긴 하다. 정확하진 않지만.
    
- NUR(Not Used Recently) Algorithm
    
    Approximated LRU 기법. (LRU보다 overhead 적게)
    
    **Bit Vector** 를 사용
    
    Bit Vector : 1. Reference bit vector(r) 페이지가 참조되었는지 여부, 2. update bit vector(m) 페이지에 값 변경이 있는지 여부. 
    
    교체 순서 (reference bit가 0인지(특정 시간 안에 참조된적 없는지)가 최우선. 같을 경우에는 이왕이면 write back 할 필요없는 page를 교체해준다.)
    
    1. (r, m) = (0, 0)
    2. (r, m) = (0, 1)
    3. (r, m) = (1, 0)
    4. (r, m) = (1, 1)
    
    **Clock algorithm (reference bit만 일단 사용)**
    
    page frame들을 순차적으로 가리키는 pointer(시계바늘)를 사용하여 교체될 page 결정
    
    해당 시계바늘일 때 reference bit 0이면 page 교체함.
    
    해당 시계바늘 일 때 reference bit 1이면 page 교체하지 않음. → 하지만 다음 시계바늘이 돌아서 올 땐 교체하기 위해서 reference bit 0으로 만들고 다음으로 이동한다.
    
    **Second Chance algorithm (reference bit, update bit 둘 다 사용)**
    
    (0,0) : page 교체
    
    (0,1) : (0,0)로 바꾼 후 이동. write-back(cleaning) list에 추가 후 이동
    
    (1,0) : (0,0)로 바꾼 후 이동.
    
    (1,1) : (0,1)로 바꾼 후 이동.


**Variable Allocation**

프로세서에게 할당하는 page수가 **가변적**임. cf. fixed allocation은 고정적이었음.

- WS (Working Set) algorithm
- PFF (Page Fault Frequency) algorithm
- VMIN (Variable MIN) algorithm

- **Working Set algorithm**
    
    프로세스가 특정 시점에 자주 참조하는 page들의 집합
    
    최근 일정시간(^: 델타)동안 참조된 page들의 집합 **(locality)**
    
    시간에 따라 변함
    
    W (t, ^)
    
    the working set of a process at time t
    
    [t-^, t] 동안 참조된 page 들의 집합
    
    ^ : window size
    
    locality에 기반을 두고 working set을 항상 메모리에 유지하기에 page fault 감소. 시스템 성능 향상
    
    ^ (window size)는 고정. memory allocation은 가변.
    

window size vs. working set size

![image](https://github.com/SSAFY11thDaejeon7/cs_study/assets/138864974/3581e02b-ebe4-4fb9-b327-cefc851e5c78)

window size 증가 초기에는 locality를 적극적으로 사용하기에, working set size가 급격히 증가하지만, 특정 시점 이후부터는 window size를 늘려도 locality에 의해 사용되는 페이지들만 계속 사용하므로 완만하게 working set 증가.

**성능 평가**

page fault 수 외에 다른 지표도 함께 봐야함.

1. page fault 횟수 * page fault 처리 비용
2. 평균 할당 page frame 수 * page frame 1개를 메모리에 유지하는 비용

**특성**

적재되는 page가 없더라도, 메모리를 반납하는 page가 있을 수 있음. (시간에 따라 working set이 변화하므로)

새로 적재되는 page가 있더라도, 교체되는 page가 없을 수 있음.

**단점**

working set management overhead

즉 page fault가 없더라도, residence set (상주 집합)을 지속적으로 관리해야하는 overhead

window size vs. page lifetime & page fault rate

![image](https://github.com/SSAFY11thDaejeon7/cs_study/assets/138864974/d061d0ca-4125-4674-b4f5-d4f24ccdcc17)

window size가 커지면, page fault가 줄어들고, 한 page의 lifetime이 길어지는 장점이 있다. 하지만 lifetime이 길어진다는 것은, 그만큼 page frame 을 메모리에 관리하는 비용도 커진다는 것을 뜻함. 그래서 trade off를 잘 생각하여 중간 지점으로 설정해야함.

- PFF (page fault frequency) algorithm
    
    **등장 배경**
    
    working set에서는 page fault가 없더라도, working set (residence set)을 상시 관리해야했다. 그래서 page fault가 일어날때만 working set(residence set)을 관리하겠다.
    
    working set 보다 low overhead 의 장점 가짐. (page fault가 발생할때만 관리)
    
    1. high page fault rate → page frame 수 증가
        
        IFT(inter-fault time) : page fault간 시간 ≤ c(타우) : threshold value
        
        기존 page들 + 추가 적재된 page들 추가 적재
        
    2. low page fault rate → page frame 수 감소
        
        IFT(inter-fault time) : page fault간 시간 > c(타우) : threshold value
        
        (tc-1, tc] 동안 참조된 page들만 유지. 나머지 page들은 메모리에서 내림.
        
- VMIN (Varialbe MIN) algorithm
    
    미래를 예측해서 [t, t+^] 동안 참조될 page들을 관리.
    
    비현실적. 불가능. 하지만 측정의 척도로 사용하기 위해 배움.
    
    최적 성능을 위한 ^값?
    
    ![image](https://github.com/SSAFY11thDaejeon7/cs_study/assets/138864974/f59841be-cbfe-4950-ac8d-148fe91efa7e)
    

Other considerations

- page size
- program restructuring
- TLB reach

- page size
    
    시스템 특성에 따라 다름.
    
    1. small page size
        
        large page table size(page수가 많아지므로) → kernel high overhead
        
        내부 단편화(internal fragmentation) 감소
        
        I/O 시간 증가. (swap device로부터 많은 page들을 읽어와야하므로)
        
        locality 향상
        
        page fault 증가
        
    2. big page size
        
        small page table size(page 수 적어짐)
        
        내부 단편화 증가
        
        I/O 시간 감소
        
        locality 저하
        
        page fault 감소
        
- program restructuring
    
    사용자가 가상 메모리 특성에 따라 프로그램을 재구성
    
    예. 2중 반복문 등에서 i,j 순서에 따라 계속해서 다른 page를 참조(page fault)하는 경우가 발생할 수 있다. 이 때 i,j 순서만 바꿔준다면 같은 page내에서 반복문을 처리하여 page fault를 감소시킬 수 있다.
    
- TLB reach
    
    TLB를 통해 접근할 수 있는 메모리의 양
    
    (number of TLB entries) * (page size)
