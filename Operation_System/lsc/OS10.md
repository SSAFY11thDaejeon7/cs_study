# [OS] Lecture 10. Virtual Memory Management

## Virtual Memory Management
- 가상 메모리 (기억장치)
  - Non0continuous allocation
    - 사용자 프로그램을 block으로 분할하여 적재/실행
  - Paging/Segmentation system
- 가상 메모리 관리의 목적
  - 가상 메모리 시스템 성능 최적화
    - Cost model
    - 다양한 최적화 기법

## Cost Model for Virtual Mem. Sys.
- Page fault frequency (발생 빈도)
- Page fault rate (발생률)
- Page fault rate를 최소화 할 수 있도록 전략들을 설계해야함
  - Context switch 및 Kernel 개입을 최소화
  - 시스템 성능 향상
- Page reference string (d)
  - 프로세스의 수행 중 참조한 페이지 번호 순서
    
  <img width="332" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/e629e874-1e73-4c7c-bec0-8aa9ca730f22">

- Page fault fate
  
  <img width="332" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/1a6f3d08-5c33-4491-8567-f7bd37f7727b">


## Hardware Components
- Address translation device (주소 사상 장치)
  - 주소 사상을 효율적으로 수행하기 위해 사용
    - E.g. TLB(associated memories), Dedicated page-table regitster, Cache memories
- Bit Vectors
  - Page 사용 상황에 대한 정보를 기록하는 비트들
  - Reference bits (used bit)
    - 참조 비트
  - Update bits (modified bits, write bits, dirty bits)
    - 갱신 비트
  <img width="310" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/44e2aa36-fb18-4473-8268-bded0a2d50f8">

## Bit Vectors
- Reference bit vector
  - 메모리에 적재된 각각의 page가 최근에 참조 되었는지를 표시
  - 운영
    1. 프로세스에 의해 참조되면 해당 page의 Ref. bit를 1로 설정
    2. 주기적으로 모든 reference bit를 0으로 초기화
  - Reference bit를 확인함으로서 최근에 참조된 page들을 확인 가능
    <img width="332" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/db760b2a-b0db-4f9d-b4e2-d32e9c80bd1f">

- Update bit vector
  - Page가 메모리에 적재된 후, 프로세스에 의해 수정되었는지를 표시
  - 주기적 초기화 없음
  - Update bit = 1
    - 해당 page의 (Main memory 상 내용) != (Swap device의 내용)
    - 해당 page에 대한 Write-back(to swap device)이 필요

## Software Components
- 가상 메모리 성능 향상을 위한 관리 기법들
  - Allocation strategies (할당 기법)
  - Fetch strategies
  - Placement strategies (배치 기법)
  - Replacement strategies (교체 기법)
  - Cleaning strategies (정리 기법)
  - Load control strategies (부하 조절 기법)

## Allocation Strategies
- 각 프로세스에게 메모리를 얼마만큼 줄 것인가?
  - Fixed allocation (고정 할당)
    - 프로세스의 실행 동안 고정된 크기의 메모리 할당
  - Variable allocation (가변 할당)
    - 프로세스의 실행 동안 할당하는 메모리의 크기가 유동적
- 고려사항
  - 프로세스 실행에 필요한 메모리 양을 예측해야 함
  - 너무 큰 메모리 할당
    - 메모리가 낭비됨
  - 너무 적은 메모리 할당
    - Page fault rate 증가
    - 시스템 성능 저하

## Fetch Strategies
- 특정 page를 메모리에 언제 적재할 것인가?
  - Demand fetch (demand paging)
    - 프로세스가 참조하는 페이지들만 적재
    - Page fault overhead
  - Anticipatory fetch (pre-paging)
    - 참조될 가능성이 높은 page 예측
    - 가까운 미래에 참조될 가능성이 높은 page를 미리 적재
    - 예측 성공 시, page fault overhead가 없음
    - Prediction overhead (Kernel의 개입), Hit ratio에 민감함
- 실제 대부분의 시스템은 Demand fetch 기법 사용
  - 일반적으로 준수한 성능을 보여줌
  - Anticipatory fetch
    - Prediction overhead, 잘못된 예측 시 자원 낭비가 큼

## Placement Strategies
- Page/segment를 어디에 적재할 것인가?
- Paging system에는 불필요
- Segmentation system에서의 배치 기법
  - First-fit
  - Best-fit
  - Worst-fit
  - Next-fit

## Replacement Strategies
- 새로운 page를 어떤 page와 교체할 것인가? (빈 page frame이 없는 경우)
  - Fixed allocation을 위한 교체 기법
  - Variable allocation을 위한 교체 기법

## Cleaning Strategies
- 변경된 page를 언제 write-back 할 것인가?
  - 변경된 내용을 swap device에 반영
  - Demand cleaning
    - 해당 page에 메모리에서 내려올 때 write-back
  - Anticipatory cleaning (pre-cleaning)
    - 더 이상 변경될 가능성이 없다고 판단할 때, 미리 write-back
    - Page 교체 시 발생하는 Write-back 시간 절약
    - Write-back 이후, page 내용이 수정되면, overhead!
- 실제 대부분의 시스템은 Demand cleaning 기법 사용
  - 일발적으로 준수한 성능을 보여줌
  - Anticipatory cleaning
    - Prediction overhead 잘못된 예측 시 자원 낭비가 큼

## Load Control Strategies
- 시스템의 multi-programming degree 조절
  - Allocation strategies와 연계됨
- 적정 수준의 multi-programming degree를 유지해야 함
  - Plateau(고원) 영역으로 유지
  - 저부하 상태 (Under-loaded)
    - 시스템 자원 낭비, 성능 저하
  - 고부하 상태 (Over-loaded)
    - 자원에 대한 경쟁 심화, 성능 저하
    - Thrashing(스레싱) 현상 발생
      - 과도한 page fault가 발생하는 현상
        <img width="539" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/7ba3ac37-ad00-42be-8845-4983ca3d644a">

## Locality
- 프로세스가 프로그램/데이터의 특정 영역을 집중적으로 참조하는 현상
- 원인
  - Loop structure in program
  - Array, structure 등의 데이터 구조
- 공간적 지역성 (Spatial locality)
  - 참조한 영역과 인접한 영역을 참조하는 특성
- 시간적 지역성 (Temporal locality)
  - 한 번 참조한 영역을 곧 다시 참조하는 특성
- 가정
  - Paging system
  - Page size = 1000 words
  - Machine instruction size = 1word
  - 주소 지정 word 단위로 이루어짐
  - 프로그램은 4번 page에 continuous allocation 됨
  - n = 1000
    <img width="516" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/3decee99-718b-4480-8358-cd02f6a3ca48">


  - 11000번의 메모리 참조 중 5개의 page만을 집중적으로 접근하게 됨

## Replacement Strategies
- Fixed allocation
  - Min(OPT, B0) algorithm
  - Random algorithm
  - FIFO(First In First Out) algorithm
  - LRU(Least Recently Used) algorithm
  - LFU(Least Frequently Used) algorithm
  - NUR(Not Used Recently) algorithm
  - Clock algorithm
  - Second chance algorithm
- Variable allocation
  - WS(Working Set) algorithm
  - PFF(Page Fault Frequency) algorithm
  - VMIN(Variable MIN) algorithm

## Min Alogorithm (OPT algorithm)
- 1966년 Belady에 의해 제시
- Minimize page fault frequency (proved)
  - Optimal solution
- 기법
  - 앞으로 가장 오랫동안 참조되지 않을 page 교체
    - Tie-breaking rule: page 번호가 가장 큰/작은 페이지 교체
  - 실현 불가능한 기법 (Unrealizable)
    - Page reference string을 미리 알고 있어야 함
  - 교체 기법의 성능 평가 도구로 사용됨
    <img width="516" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/88319485-1c52-48ec-a586-d43b1e9119f1">
    <img width="551" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/74248c7b-6aec-421d-a239-c736d5876ba4">


## Random Algorithm
- 무작위로 교체할 page 선택
- Low overhead
- No policy
  <img width="429" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/98e7f0cb-f08b-4e61-86d2-db47216b7eda">


## FIFO Algorithm
- First In First Out
  - 가장 오래된 page를 교체
- Page가 적재된 시간을 기억하고 있어야 함
- 자주 사용되는 page가 교체될 가능성이 높음
  - Locality에 대한 고려가 없음
- FIFO anomaly (Belady's anomaly)
  - FIFO 알고리즘의 경우, 더 많은 page frame을 할당 받음에도 불구하고 page fault의 수가 증가하는 경우가 있음
    
    <img width="516" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/1469827c-4361-45e4-a19c-54f69d776220">
    <img width="516" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/e41f18ff-6b69-4155-8a40-d518ca925388">
    <img width="578" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/84dba1e4-d9e2-4a9c-8e82-74b3bb391af8">


## LRU (Least Recently Used) Algorithm
- 가장 오랫동안 참조되지 않은 page를 교체
- Page 참조시 마다 시간을 기록해야 함
- Locality에 기반을 둔 교체 기법
- MIN algorithm에 근접한 성능을 보여줌
- 실제로 가장 많이 활용되는 기법
- 단점
  - 참조시마다 시간을 기록해야 함 (Overhead)
    - 간소화된 정보 수집으로 해소 가능
      - 예) 정확한 시간 대신, 순서만 기록
  - Loop 실행에 필요한 크기보다 작은 수의 page frame이 할당된 경우, page fault 수가 급격히 증가함
    - 예) loop를 위한 |Ref. string| = 4 / 할당된 page frame이 3개
    - Allocation 기법에서 해결해야 함
      <img width="580" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/0827816c-b356-4dde-bb73-0adf8648de66">
      <img width="461" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/863c971f-9caf-43cf-a02a-69b913686c92">


## LFU (Least Frequency Used) Algorithm
- 가장 참조 횟수가 적은 page를 교체
  - Tie-breaking rule : LRU
- Page 참조 시 마다, 참조 횟수를 누적 시켜야 함
- Locality 활용
  - LRU 대비 적은 overhead
- 단점
  - 최근 적재된 참조될 가능성이 높은 page가 교체될 가능성이 있음
  - 참조 횟수 누적 overhead
    <img width="576" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/0ccb4c3d-9ee3-48f5-86da-521070abaded">
    <img width="485" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/9065e9c7-408f-4636-a99a-ff5b6ed5be35">


## NUR (Not Used Recently) Algorithm
- LRU approximation scheme
  - LRU보다 적은 overhead로 비슷한 성능 달성 목적
- Bit vector 사용
  - Reference bit vector (r), Update bit vector (m)
- 교체 순서
  1. (r, m) = (0, 0)
  2. (r, m) = (0, 1)
  3. (r, m) = (1, 0)
  4. (r, m) = (1, 1)
  <img width="550" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/4fcd2f7e-cf53-4fcb-8c6e-b83f919dca58">


## Clock Algorithm
- IBM VM/370 OS
- Reference bit 사용함
  - 주기적인 초기화 없음
- Page frame들을 순차적으로 가리키는 pointer(시계바늘)를 사용하여 교체될 page 결정
  <img width="371" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/b3e06473-8efc-41d7-b95a-03fd8066b83c">
  <img width="601" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/7f696c86-fc15-4bd8-9ac0-49def19c42b5">


- Pointer를 돌리면서 교체 page 결정
  - 현재 가리키고 있는 page의 reference bit(r) 확인
  - r = 0인 경우, 교체 page로 결정
  - r = 1인 경우, reference bit 초기화 후 pointer 이동
- 먼저 적재된 page가 교체될 가능성이 높음
  - FIFO와 유사
- Reference bit를 사용하여 교체 페이지 결정
  - LRU(or NUR)과 유사

## Second Chance Algorithm
- Clock algorithm과 유사
- Update bit(m)도 함께 고려함
  - 현재 가리키고 있는 page의 (r, m) 확인
  - (0, 0): 교체 page로 결정
  - (0, 1): -> (0, 0), write-back(cleaning) list에 추가 후 이동
  - (1, 0): -> (0, 0) 후 이동
  - (1, 1): -> (0, 1) 후 이동
  <img width="385" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/28cbd30d-e9f2-4f34-aa0e-94e7f4f8c6a9">
  <img width="601" alt="image" src="https://github.com/SSAFY11thDaejeon7/cs_study/assets/68500724/866e4774-1f8f-486d-975d-20deae9e9914">


## Other Algorithms
- Additional-reference-bits algorithm
  - LRU approximation
  - 여러 개의 reference bit를 가짐
    - 각 time-interval에 대한 참조 여부 기록
    - History register for each page
- MRU(Most Recently Used) algorithm
  - LRU와 정반대 기법
- MFU(Most Frequently Used) algorithm
  - LFU와 정반대 기법
